\documentclass[addpoints]{exam}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{venndiagram}
\usepackage{graphicx}
\usepackage{mleftright}

% Header and footer.
\pagestyle{headandfoot}
\runningheadrule
\runningfootrule
\runningheader{HW1}{Linear Algebra}{}
\runningfooter{}{Page \thepage\ of \numpages}{}
\firstpageheader{}{}{}

\boxedpoints
\printanswers
\qformat{} %Comment this to number questions, uncomment this to not number questions

\newcommand\union\cup
\newcommand\inter\cap

\title{Linear Algebra\\ Homework 3 part i}
\author{Ali Muhammad Asad}

\begin{document}
\maketitle
\begin{sloppypar}
\section*{\textbf{Chapter 1 : Linear Equations and Matrices}}
\subsection*{\textbf{Ex Set 1.3: Matrices and Matrix Operations}}
% \vspace{1mm}
\begin{questions}
    \question
    \textbf{18. } \\ 
    (a) Show that if $A$ has a row of zeroes, and $B$ is any matrix for which $AB$ is defined, then $AB$ also has a row of zeroes. \\ 
    (b) Find a similar result involving a column of zeroes.
    \begin{solution}
        
        (a) Let $A$ be an $ m \times n $ matrix. Then for $AB$ to be defined, $B$ is an $ n \times p $ matrix. \\ 
        We claim that the $ i $th row of $AB$ is a row of zeroes. Then by definition of multiplication of matrices, an entry $ c_{ij} $ in the $ i $th row of $AB$ should be: \\ 
        $ c_{ij} = a_{i1}b_{1j} + a_{i2}b_{2j} + ... + a_{in}b_{nj} = \displaystyle\sum_{k = 1}^{n} a_{ik}b_{kj} $. \\ 
        Since the $i$th row of $A$ is zero, we have $ a_{i1} = a_{i2} = ... = a_{in} = 0 $ \\ 
        $ \implies c_{ij} = 0b_{1j} + 0b_{2k} + ... + 0b_{nj} = \displaystyle\sum_{k = 1}^{n} 0b_{kj} = 0$. \\ 
        Hence the $ i $th row of $AB$ is a row of zeroes.

        \vspace{2mm}
        (b) In general if $ A = [a_{ij}] $ is an $ n \times p $ matrix and $ B = [b_{ij}] $ is an $ m \times n $ matrix. We claim that the $ j $th column of $BA$ is a column of zeroes, then the $ j $th column of $A$ must be a column of zeroes. \\ 
        $ BA = \begin{bmatrix}
            b_{11} & b_{12} & \cdots & b_{1n} \\ 
            b_{21} & b_{22} & \cdots & b_{2n} \\ 
            \vdots & \vdots & & \vdots \\ 
            b_{m1} & b_{m2} & \cdots & b_{mn}
        \end{bmatrix} \begin{bmatrix}
            a_{11} & a_{12} & \cdots & a_{1j} & \cdots & a_{1p} \\ 
            a_{21} & a_{22} & \cdots & a_{2j} & \cdots & a_{2p} \\ 
            \vdots & \vdots & & \vdots & & \vdots \\ 
            a_{n1} & a_{n2} & \cdots & a_{nj} & \cdots & a_{np} 
        \end{bmatrix}$ \\ 
        Then the $j$th column of the matrix can be represented in the form of a column vector: \\ 
        $ j $th $ = \begin{bmatrix}
            b_{11}a_{1j} + b_{12}a_{2j} + ... b_{1n}a_{nj} \\ 
            b_{21}a_{1j} + b_{22}a_{2j} + ... b_{2n}a_{nj} \\
            \vdots \\ 
            b_{m1}a_{1j} + b_{m2}a_{2j} + ... b_{mn}a_{nj}
        \end{bmatrix} $ \\ 
        Let the $j$th row of $A$ be a column of zero, so we have $ a_{1j} = a_{2j} = ... = a_{nj} = 0 $. \\ 
        Therefore, our $j$th column of the matrix as represented by a column vector becomes $ \begin{bmatrix}
            b_{11}0 + b_{12}0 + ... b_{1n}0 \\ 
            b_{21}0 + b_{22}0 + ... b_{2n}0 \\ 
            \vdots \\ 
            b_{m1}0 + b_{m2}0 + ... b_{mn}0
        \end{bmatrix} = \begin{bmatrix}
            0 \\ 0 \\ \vdots \\ 0
        \end{bmatrix}$ \\ Hence the $j$th column of the matrix $BA$ is a column of zeroes if the $j$th column of $A$ is a column of zeroes. 
    \end{solution}
    
    \question
    \textbf{19. } Let $A$ be any $ m \times n $ matrix and let 0 be the $ m \times n $ matrix each of whose entries is zero. Show that if $kA = 0$, then $ k = 0 $ or $ A = 0 $.
    \begin{solution}
        Let $ A = \begin{bmatrix}
            a_{11} & a_{12} & \cdots & a_{1n} \\ 
            a_{21} & a_{22} & \cdots & a_{2n} \\ 
            \vdots & \vdots & & \vdots \\ 
            a_{m1} & a_{m2} & \cdots & a_{mn}
        \end{bmatrix}$\\
        If $ kA = 0 $, then every element of $kA$ is zero. \\ 
        Then $ kA = k\begin{bmatrix}
            a_{11} & a_{12} & \cdots & a_{1n} \\ 
            a_{21} & a_{22} & \cdots & a_{2n} \\ 
            \vdots & \vdots & & \vdots \\ 
            a_{m1} & a_{m2} & \cdots & a_{mn}
        \end{bmatrix} = 0 \implies ka_{ij} = 0 \; [\forall i, j \geq 0 \; | \; i \leq m, j \leq n]$ \\ 
        This is only possible if and only if $ k = 0 $, in which case all entries of $A$ are multiplied by 0 and we get the zero matrix as required. \\ 
        Or if all entries of $A$ are zero, that is $ a_{ij} = 0 \; [\forall i, j \geq 0 \; | \; i \leq m, j \leq n] $\\ 
        Therefore, for $ kA = 0 $ to be true, either $k = 0$ or $A = 0$
    \end{solution}

    \question
    \textbf{25. } Prove: If $A$ and $B$ are $ n \times n $ matrices, then tr$ (A + B)  = \text{tr}(A) + \text{tr}(B)$.
    \begin{solution}
        By definition, the \textbf{\textit{trace of $A$}}, denoted by tr$(A)$, is defined to be the sum of the entries on the main diagonal of $A$. Therefore, trace is only defined for square matrices. \\ 
        Let $ A = \begin{bmatrix}
            a_{11} & a_{12} & \cdots & a_{1n} \\ 
            a_{21} & a_{22} & \cdots & a_{2n} \\ 
            \vdots & \vdots & & \vdots \\ 
            a_{n1} & a_{n2} & \cdots & a_{nn}
        \end{bmatrix} $ and $ B = \begin{bmatrix}
            b_{11} & b_{12} & \cdots & b_{1n} \\ 
            b_{21} & b_{22} & \cdots & b_{2n} \\ 
            \vdots & \vdots & & \vdots \\ 
            b_{n1} & b_{n2} & \cdots & b_{nn}
        \end{bmatrix} $ \\ 
        Then tr$(A) = a_{11} + a_{22} + ... + a_{nn}$ and tr$(B) = b_{11} + b_{22} + ... + b_{nn}$. \\ 
        Then tr($A$) + tr($B$) = $ a_{11} + a_{22} + ... + a_{nn} + b_{11} + b_{22} + ... + b_{nn} $. 

        \vspace{3mm}
        $ A + B = \begin{bmatrix}
            a_{11} + b_{11} & a_{12} + b_{12} & \cdots & a_{1n} + b_{1n} \\ 
            a_{21} + b_{21} & a_{22} + b_{22} & \cdots & a_{2n} + b_{2n} \\ 
            \vdots & \vdots & & \vdots \\ 
            a_{n1} + b_{n1} & a_{n2} + b_{n2} & \cdots & a_{nn} + b_{nn} 
        \end{bmatrix} $ \\ 
        Then tr($A+B$) = $ a_{11} + b_{11} + a_{22} + b_{22} + ... + a_{nn} + b_{nn} $ which is the same as tr($A$) + tr($B$). Hence proved.

    \end{solution}

\end{questions}
\end{sloppypar}
\end{document}

% $ \renewcommand\arraystretch{1.3}
%     \mleft[
%     \begin{array}{cccc|cccc}

%     \end{array}
%     \mright]  
%     $